# AI Cognitive Preservation Guidelines

These guidelines are designed to help individuals and teams use AI tools effectively while protecting cognitive depth and judgment.

---

## Foundation Building
- **Build Before Borrowing**: Develop domain expertise before leaning on AI.  
- **Calibrate on Known Territory**: Test AI on familiar tasks first to expose its strengths and weaknesses.  
- **Own Your Outputs**: If your name is on it, verify it.  

---

## Tool Mastery
- **Understand Your Tools**: Know their strengths, limits, and biases.  
- **Curate Your Context**: Garbage in = garbage out.  
- **Every AI Tool Is Different — Learn the Dance**: Treat AI like a dialogue, not a one-click answer.  
- **Embrace Productive Friction**: Easy answers weaken thinking muscles.  

---

## Cognitive Protection
- **Question Authority**: AI confidence ≠ accuracy.  
- **Maintain Executive Control**: You set the agenda; AI supports.  
- **Detect Dependency Early**: Try “AI fasting” to keep your edge.  

---

## Quality Assurance
- **Diversify Your Counsel**: Use multiple AI perspectives and seek contrarian views.  
- **Verify Before Amplifying**: Never share AI content without verification.  
- **Document Your Journey**: Track how AI affects your thinking and learning.  

---

## Pitfalls I’ve Seen (and Lived)
- **Confidence Trap**: Mistaking AI’s tone for truth.  
- **Intimacy Illusion**: Building false trust in agreeable AI systems.  
- **Productivity Paradox**: Speeding up, but thinking less.  
- **Verification Gap**: Sharing AI content without understanding its failure modes.  

### Real-world examples
- **Bahamas restaurant story**: AI confidently fabricated a non-existent restaurant.  
- **Pi.ai conversations**: Demonstrated how easy it is to fall into intimacy illusion.  

---

## Warning Signs of Cognitive Debt
- Decreased tolerance for complexity.  
- Reduced ability to recreate work without AI.  
- Over-trust in a single system’s outputs.  
- Struggling to explain reasoning steps.  

---

## Implementation Strategies

### Individual
- Use AI selectively for acceleration, not for substitution.  
- Build checkpoints: pause to reflect without AI.  
- Practice “AI fasting” days.  

### Team
- Encourage shared verification before adoption.  
- Document how AI tools are used in workflows.  
- Assign rotating “AI skeptic” roles to catch blind spots.  

---

## Ethical Reflection
In creating a “virtual Dr. Kosmyna” to reflect on her paper *Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task*, I realized that even simulating a real person raises ethical questions about digital footprints, representation, and consent.  

**New guideline to consider:** Respecting Digital Personhood — be transparent when simulating real individuals, and treat their digital presence with care.  

---

## Summary
These principles are not perfect. I fail at them often. But they help me avoid trading depth for speed when using AI. They’re shared here so others can adapt, improve, and expand on them.